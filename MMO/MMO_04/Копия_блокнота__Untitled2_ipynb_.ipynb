{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46687b5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Импорт библиотеки numpy для работы с числовыми массивами и математическими операциями.\n",
    "# Нужно для обработки данных, например, для замены нулевых значений медианой.\n",
    "import numpy as np\n",
    "\n",
    "# Импорт функций train_test_split и GridSearchCV из scikit-learn.\n",
    "# train_test_split разделяет данные на обучающую и тестовую выборки.\n",
    "# GridSearchCV используется для подбора оптимальных гиперпараметров модели (лекция, стр. 22).\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Импорт модели логистической регрессии из scikit-learn.\n",
    "# Это линейный классификатор, разделяющий классы гиперплоскостью (лекция, стр. 5; ответ 1).\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Импорт модели метода опорных векторов (SVC) из scikit-learn.\n",
    "# SVC — ещё один линейный классификатор, максимизирующий зазор между классами (лекция, стр. 13; ответ 1).\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Импорт модели дерева решений из scikit-learn.\n",
    "# Используется для сравнения с линейными классификаторами, как требует лабораторная (стр. 1, задание 3).\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Импорт модели k-ближайших соседей (KNN) из scikit-learn.\n",
    "# Также для сравнения с линейными классификаторами (лабораторная, стр. 1, задание 3).\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Импорт метрик для оценки качества модели: accuracy, precision, recall, confusion matrix.\n",
    "# Метрики нужны для анализа производительности моделей (лекция, стр. 23; ответ 6).\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "# Импорт RocCurveDisplay для построения ROC-кривых.\n",
    "# ROC-кривые позволяют сравнить модели по их предсказательной способности (лекция, стр. 25; ответ 7).\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# Импорт matplotlib.pyplot для визуализации графиков (ROC-кривых).\n",
    "# Используется для отображения результатов в Google Colab (лабораторная, стр. 1, задание 4).\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка датасета diabetes (1).csv в pandas DataFrame.\n",
    "# Датасет содержит признаки (Pregnancies, Glucose и др.) и целевую переменную Outcome (0 или 1).\n",
    "# В Google Colab файл нужно предварительно загрузить через интерфейс или Google Drive.\n",
    "data = pd.read_csv('diabetes (1).csv')\n",
    "\n",
    "# Предобработка данных: определение столбцов, где нули считаются некорректными.\n",
    "# Нулевые значения в Glucose, BloodPressure, SkinThickness, Insulin, BMI нереалистичны (например, нулевой уровень глюкозы невозможен).\n",
    "columns_with_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# Цикл для замены нулей медианой в указанных столбцах.\n",
    "# Медиана используется, чтобы минимизировать влияние выбросов и сохранить распределение данных.\n",
    "for col in columns_with_zeros:\n",
    "    data[col] = data[col].replace(0, data[col].median())  # Замена нулей на медиану столбца.\n",
    "\n",
    "# Разделение данных на признаки (X) и целевую переменную (y).\n",
    "# X содержит все столбцы, кроме Outcome, который является целевой переменной.\n",
    "X = data.drop('Outcome', axis=1)  # Признаки (все столбцы, кроме Outcome).\n",
    "y = data['Outcome']  # Целевая переменная (Outcome: 0 — нет диабета, 1 — есть диабет).\n",
    "\n",
    "# Разделение данных на обучающую (80%) и тестовую (20%) выборки.\n",
    "# test_size=0.2 задаёт долю тестовой выборки, random_state=42 обеспечивает воспроизводимость.\n",
    "# Это нужно для оценки обобщающей способности модели (лекция, стр. 7).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Начало блока логистической регрессии (задание 1 лабораторной).\n",
    "print(\"=== Logistic Regression ===\")\n",
    "\n",
    "# Создание модели логистической регрессии с параметрами по умолчанию (C=1, L2-регуляризация).\n",
    "# max_iter=1000 увеличивает количество итераций для сходимости, random_state=42 для воспроизводимости.\n",
    "# Логистическая регрессия — линейный классификатор, использующий сигмоидную функцию (лекция, стр. 5–6; ответ 1).\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Обучение модели на тренировочных данных.\n",
    "# Модель подстраивает веса w и смещение b, чтобы разделить классы гиперплоскостью.\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Вывод заголовка для результатов модели с параметрами по умолчанию.\n",
    "print(\"Default (C=1, L2):\")\n",
    "\n",
    "# Вычисление и вывод точности (accuracy) на обучающей выборке.\n",
    "# Accuracy = доля правильных предсказаний (лекция, стр. 23).\n",
    "print(f\"Training accuracy: {lr_model.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вычисление и вывод точности на тестовой выборке.\n",
    "# Тестовая точность показывает, как модель обобщается на новых данных.\n",
    "print(f\"Test accuracy: {lr_model.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Эксперимент с параметром C=100 (лабораторная, стр. 1).\n",
    "# C=100 означает меньшую регуляризацию, модель старается классифицировать больше точек правильно.\n",
    "# Это может привести к переобучению (ответ 4).\n",
    "lr_model_c100 = LogisticRegression(C=100, max_iter=1000, random_state=42)\n",
    "\n",
    "# Обучение модели с C=100 на тренировочных данных.\n",
    "lr_model_c100.fit(X_train, y_train)\n",
    "\n",
    "# Вывод заголовка для результатов с C=100.\n",
    "print(\"\\nWith C=100:\")\n",
    "\n",
    "# Вывод точности на обучающей выборке для C=100.\n",
    "# Высокий C может дать высокую точность на тренировке, но ниже на тесте из-за переобучения.\n",
    "print(f\"Training accuracy: {lr_model_c100.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вывод точности на тестовой выборке для C=100.\n",
    "print(f\"Test accuracy: {lr_model_c100.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Эксперимент с параметром C=0.01 (лабораторная, стр. 1).\n",
    "# C=0.01 означает сильную регуляризацию, модель упрощается, игнорируя выбросы.\n",
    "# Это может привести к недообучению (ответ 4).\n",
    "lr_model_c001 = LogisticRegression(C=0.01, max_iter=1000, random_state=42)\n",
    "\n",
    "# Обучение модели с C=0.01 на тренировочных данных.\n",
    "lr_model_c001.fit(X_train, y_train)\n",
    "\n",
    "# Вывод заголовка для результатов с C=0.01.\n",
    "print(\"\\nWith C=0.01:\")\n",
    "\n",
    "# Вывод точности на обучающей выборке для C=0.01.\n",
    "# Низкий C может снизить точность из-за избыточной регуляризации.\n",
    "print(f\"Training accuracy: {lr_model_c001.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вывод точности на тестовой выборке для C=0.01.\n",
    "print(f\"Test accuracy: {lr_model_c001.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Выбор лучшей модели логистической регрессии (C=1, L2-регуляризация).\n",
    "# C=1 выбран как баланс между переобучением и недообучением на основе результатов.\n",
    "# L2-регуляризация (penalty='l2') штрафует большие веса, предотвращая переобучение (лекция, стр. 8; ответ 3).\n",
    "lr_best = LogisticRegression(C=1, penalty='l2', max_iter=1000, random_state=42)\n",
    "\n",
    "# Обучение лучшей модели на тренировочных данных.\n",
    "lr_best.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание классов на тестовой выборке для лучшей модели.\n",
    "# Предсказания нужны для вычисления метрик качества.\n",
    "y_pred_lr = lr_best.predict(X_test)\n",
    "\n",
    "# Вывод заголовка для метрик лучшей модели логистической регрессии.\n",
    "print(\"\\nBest Logistic Regression Metrics (C=1, L2):\")\n",
    "\n",
    "# Вычисление и вывод точности (accuracy) на тестовой выборке.\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN) (лекция, стр. 23).\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.2f}\")\n",
    "\n",
    "# Вычисление и вывод точности (precision) на тестовой выборке.\n",
    "# Precision = TP / (TP + FP), показывает долю правильных положительных предсказаний.\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_lr):.2f}\")\n",
    "\n",
    "# Вычисление и вывод полноты (recall, sensitivity) на тестовой выборке.\n",
    "# Recall = TP / (TP + FN), показывает, как хорошо модель находит положительные примеры (лекция, стр. 23; ответ 6).\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_lr):.2f}\")\n",
    "\n",
    "# Вывод заголовка для матрицы ошибок.\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "# Вычисление и вывод матрицы ошибок.\n",
    "# Матрица показывает TP, FP, FN, TN, позволяя вычислить чувствительность и специфичность (ответ 6).\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# Начало блока метода опорных векторов (SVC, задание 2 лабораторной).\n",
    "print(\"\\n=== Support Vector Classifier ===\")\n",
    "\n",
    "# Создание модели SVC с параметрами по умолчанию (C=1, gamma='scale', ядро RBF).\n",
    "# SVC максимизирует зазор между классами, используя гиперплоскость (лекция, стр. 13; ответ 1).\n",
    "svc_model = SVC(random_state=42)\n",
    "\n",
    "# Обучение модели SVC на тренировочных данных.\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Вывод заголовка для результатов модели SVC по умолчанию.\n",
    "print(\"Default SVC:\")\n",
    "\n",
    "# Вывод точности на обучающей выборке для SVC.\n",
    "print(f\"Training accuracy: {svc_model.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вывод точности на тестовой выборке для SVC.\n",
    "print(f\"Test accuracy: {svc_model.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Настройка поиска по сетке для подбора параметров C и gamma (лабораторная, стр. 1).\n",
    "# C контролирует регуляризацию, gamma влияет на форму разделяющей поверхности (лекция, стр. 21; ответ 4).\n",
    "SVC_params = {\"C\": [0.1, 1, 10], \"gamma\": [0.2, 0.6, 1]}\n",
    "\n",
    "# Создание объекта GridSearchCV для SVC.\n",
    "# cv=5 задаёт 5-кратную кросс-валидацию, n_jobs=-1 использует все доступные ядра процессора.\n",
    "# GridSearchCV находит лучшую комбинацию параметров (ответ 5).\n",
    "svc_grid = GridSearchCV(SVC(random_state=42), SVC_params, cv=5, n_jobs=-1)\n",
    "\n",
    "# Выполнение поиска по сетке на тренировочных данных.\n",
    "# Это может занять время, так как проверяются все комбинации параметров.\n",
    "svc_grid.fit(X_train, y_train)\n",
    "\n",
    "# Вывод заголовка для результатов лучшей модели SVC.\n",
    "print(\"\\nBest SVC Parameters:\")\n",
    "\n",
    "# Вывод лучшего среднего значения точности на кросс-валидации.\n",
    "# Это показывает, насколько хорошо модель обобщается.\n",
    "print(f\"Best CV score: {svc_grid.best_score_:.2f}\")\n",
    "\n",
    "# Вывод лучших найденных параметров C и gamma.\n",
    "print(f\"Best params: {svc_grid.best_params_}\")\n",
    "\n",
    "# Получение лучшей модели SVC из GridSearchCV.\n",
    "svc_best = svc_grid.best_estimator_\n",
    "\n",
    "# Предсказание классов на тестовой выборке для лучшей модели SVC.\n",
    "y_pred_svc = svc_best.predict(X_test)\n",
    "\n",
    "# Вывод точности на обучающей выборке для лучшей модели SVC.\n",
    "print(f\"Training accuracy (best): {svc_best.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вывод точности на тестовой выборке для лучшей модели SVC.\n",
    "print(f\"Test accuracy (best): {svc_best.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Вывод заголовка для метрик лучшей модели SVC.\n",
    "print(\"\\nBest SVC Metrics:\")\n",
    "\n",
    "# Вычисление и вывод точности на тестовой выборке.\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svc):.2f}\")\n",
    "\n",
    "# Вычисление и вывод точности (precision) на тестовой выборке.\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_svc):.2f}\")\n",
    "\n",
    "# Вычисление и вывод полноты (recall) на тестовой выборке.\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_svc):.2f}\")\n",
    "\n",
    "# Вывод заголовка для матрицы ошибок.\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "# Вычисление и вывод матрицы ошибок для лучшей модели SVC.\n",
    "print(confusion_matrix(y_test, y_pred_svc))\n",
    "\n",
    "# Начало блока для дерева решений и k-ближайших соседей (задание 3 лабораторной).\n",
    "print(\"\\n=== Decision Tree ===\")\n",
    "\n",
    "# Создание модели дерева решений с параметрами по умолчанию.\n",
    "# Дерево решений — нелинейный классификатор, не обсуждается в лекции, но требуется в лабораторной.\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Обучение модели дерева решений на тренировочных данных.\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Вывод точности на обучающей выборке для дерева решений.\n",
    "# Деревья часто переобучаются, давая высокую точность на тренировке.\n",
    "print(f\"Training accuracy: {dt_model.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вывод точности на тестовой выборке для дерева решений.\n",
    "print(f\"Test accuracy: {dt_model.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Начало блока для k-ближайших соседей (KNN).\n",
    "print(\"\\n=== K-Nearest Neighbors ===\")\n",
    "\n",
    "# Создание модели KNN с параметрами по умолчанию (n_neighbors=5).\n",
    "# KNN — нелинейный метод, основанный на расстоянии до ближайших точек.\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "# Обучение модели KNN на тренировочных данных.\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Вывод точности на обучающей выборке для KNN.\n",
    "print(f\"Training accuracy: {knn_model.score(X_train, y_train):.2f}\")\n",
    "\n",
    "# Вывод точности на тестовой выборке для KNN.\n",
    "print(f\"Test accuracy: {knn_model.score(X_test, y_test):.2f}\")\n",
    "\n",
    "# Начало блока для построения ROC-кривых (задание 4 лабораторной).\n",
    "# Создание фигуры и осей для графика ROC-кривых.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Построение ROC-кривой для лучшей модели логистической регрессии.\n",
    "# ROC-кривая показывает зависимость TPR (чувствительность) от FPR (1-специфичность) (лекция, стр. 25; ответ 7).\n",
    "RocCurveDisplay.from_estimator(lr_best, X_test, y_test, ax=ax, name='Logistic Regression')\n",
    "\n",
    "# Построение ROC-кривой для лучшей модели SVC.\n",
    "RocCurveDisplay.from_estimator(svc_best, X_test, y_test, ax=ax, name='SVC')\n",
    "\n",
    "# Построение ROC-кривой для модели дерева решений.\n",
    "RocCurveDisplay.from_estimator(dt_model, X_test, y_test, ax=ax, name='Decision Tree')\n",
    "\n",
    "# Построение ROC-кривой для модели KNN.\n",
    "RocCurveDisplay.from_estimator(knn_model, X_test, y_test, ax=ax, name='KNN')\n",
    "\n",
    "# Установка заголовка графика ROC-кривых.\n",
    "plt.title(\"ROC Curves for Different Models\")\n",
    "\n",
    "# Отображение графика в Google Colab.\n",
    "# Модель с кривой, ближайшей к верхнему левому углу, имеет лучший AUC и считается лучшей (ответ 7).\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
